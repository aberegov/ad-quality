Running simulation is easy but it takes some time to prepare the data.

Data Preparation
================
I would recommend using a local copy of Postgres database for the simulation data.
GreenPlum is very unresponsive from time to time.

1) Create a schema for the simulation data
    - replace username aberegov with another name
    - run data/sql/create_adquality_schema.sql

2) Extract predictors data from the analytics prod and import the predictors into the local database
    - run data/sql/extract_predictors.sql script to dump data to CSV file
    - use pgAdmin or DbVisualizer to load CSV file into table (both tools provide such capability)

3) Extract impressions and IAS data and import it into the local database
    - run data/sql/extract_impressions.sql to dump data to CSV file
    - use pgAdmin or DbVisualizer to load CSV file into table (both tools provide such capability)

Mini tutorial how to dump table's data from GreenPlum
------------------------------------------------------
psql -h <GreenPlum host> -d vds_prd -U <your username>

vrd_prd => \f ","
vrd_prd => \a
vrd_prd => \o <path to the file name>
vrd_prd => <ENTER SQL>
vrd_prd => \q

Python Environment
==================

Additional Packages
-------------------
You need to install the following packages
    (1) matplotlib
    (2) unittest

Connection to Database
-----------------------
In your home directory create .env file and add the below lines:

[database]
login=<username>
password=<password>
host=localhost
database=postgres


Running Simulations
===================
Run python script com.conversant.simulators.ViewabilitySimulator.py

